---
title: "SDS230_FinalProject"
author: "Tejita Agarwal, Lelan Hu, Franklin She"
date: "5/5/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Packages
library(plyr)
library(car)
library(leaps)
library(PerformanceAnalytics)
source("http://www.reuningscherer.net/s&ds230/Rfuncs/regJDRS.txt")
```

**Introduction**
Background and motivation, not more than a short paragraph

**Data**
*The data used in this analysis were collected in a survey of students in two secondary schools. It includes information about gender, social habits, alcohol consumption, grades, etc.

The variables used in this analysis are:
1. school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira); categorical
2. sex - student's sex (binary: 'F' - female or 'M' - male); categorical
3. age - student's age (numeric: from 15 to 22); continuous\*
4. studytime - weekly study time (numeric: 1 - 10 hours); continuous\*
5. higher - wants to take higher education (binary: yes or no); categorical
6. freetime - free time after school (numeric: from 1 - very low to 5 - very high); continuous\*
7. goout - going out with friends (numeric: from 1 - very low to 5 - very high); continuous\*
8. Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high); continuous\*
9. Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high); continuous\*
10. health - current health status (numeric: from 1 - very bad to 5 - very good); continuous\*
11. absences - number of school absences (numeric: from 0 to 93); continuous\*
12. grade - final grade (numeric: from 0 to 20); continuous\*

\*(discrete integers, makes sense to be treated as continuous variable, because of the nature of the variable)

*
**Data Cleaning Process**
Our data did not require much cleaning. We renamed the column G3 to "grade" to provide a more intuitive and clear description of what the variable was and removed observations where grade was 0 because this unreasonable grade indicated that the data for these observations was incomplete. 

```{r}
all_data <- read.csv("student-por.csv", header=TRUE)
selected_data <- all_data[, c("school", "sex", "age", "studytime", "higher", "freetime", "goout", "Dalc", "Walc", "health", "absences", "G3")]

# rename G3 to grade
selected_data <- rename(selected_data, c("G3"="grade"))

# remove observations where grade is 0
selected_data <- selected_data[selected_data$grade != 0,]

nrow(selected_data)
names(selected_data)
head(selected_data)
str(selected_data)

attach(selected_data)
```


**Descriptive Plots**
```{r}
# boxplots of grade by school and by sex (with superimposed mean)
boxplot(grade ~ school, main = "Boxplot of Grades by School", ylab = "Grade / Scale(0 - 20)", col = "lightblue", xlab = "School")
means <- tapply(grade, school, mean)
points(means, col = "red", pch = 19, cex = 1.2)
text(x = c(1:6), y = means + 1, labels = round(means,1))

boxplot(grade ~ sex, main = "Boxplot of Grades by Sex", ylab = "Grade / Scale(0 - 20)", col = "green", xlab = "Sex")
means <- tapply(grade, sex, mean)
points(means, col = "red", pch = 19, cex = 1.2)
text(x = c(1:6), y = means + 1, labels = round(means,1))


# scatterplots of grade and alcohol consumption (weekend and weekday)
plot(jitter(grade, factor = 1), jitter(Walc), pch = 19, col = "red", xlab = "Grade",
     ylab = "Weekend Alcohol Consumption", cex = 0.5)
mtext("Weekend Alcohol Consumption vs. Grade", cex = 1.2, line = 1)
mtext(paste("Sample Correlation =", round(cor(age, Walc), 3)), cex = 1.2, line = 0)

plot(jitter(grade, factor = 1), jitter(Dalc), pch = 19, col = "blue", xlab = "Grade",
     ylab = "Weekday Alcohol Consumption", cex = 0.5)
mtext("Weekday Alcohol Consumption vs. Grade", cex = 1.2, line = 1)
mtext(paste("Sample Correlation =", round(cor(age, Dalc), 3)), cex = 1.2, line = 0)

# histogram of grade
hist(grade, main = "Histogram of Grades", xlab = "Grade (0 - 20)", xlim = c(0, 20), col = "orange")
hist(freetime + 0.1, main = "Histogram of Freetime", xlab = "Freetime", col = "orange", breaks = 5)
hist(goout + 0.1, main = "Histogram of Going Out", xlab = "Time Going Out With Friends)", col = "orange", breaks = 5)

chart.Correlation(selected_data[, c(3,4,6:12)], histogram = TRUE, pch = 19)
##might be useful to transform Walc, Dalc, and absences. for now, I will try a sqrt transformation of abs, and log transformation of Walc and Dalc. 


transdata <- selected_data[, c(3,4,6:12)]
transdata$logWalc <- log(transdata$Walc + 1)
transdata$logDalc <- log(transdata$Dalc + 1)
transdata$sqrtabs <- sqrt(transdata$absences)
chart.Correlation(transdata[, c(1:4,7,9:12)], histogram = TRUE, pch = 19)

```

**Summary Information**
*(idk for sure what goes here) Our preliminary descriptive plots show that grades, freetime, and time going out are appear to be approximately normally distributed. The box plots indicate there may be significant difference in the mean of grades between the two schools and between females and males. Our initial matrix plot indicates that transformations of the variables absences, Dalc, and Walc may be helpful. These three variables all appear strongly right skewed. This was expected for Walc and Dalc, which measure alcohol consumption, because many students reported that they do not consume any alcohol. As expected, there is a strong correlation between Walc and Dalc on both the raw and log scale and this indicates that collinearity may need to be considered in our models. (idk if this is like...correct. pls help) Interestingly, there does not appear to be a singificant correlation between age and grades. (pls add more) *

**Analysis**
Basic tests - t-test, correlation, AND ability to create bootstrap confidence interval for either a t-test or a correlation.
Permutation Test – include at least one.
Multiple Regression – use either backwards stepwise regression or some form of best subsets regression. Should include residual plots. A GLM with a mix of continuous and categorical predictors is fine here.
AT LEAST ONE OF THE FOLLOWING TECHNIQUES – ANOVA, ANCOVA, Logistic Regression, Multinomial Regression, OR data scraping off a website.
```{r}
# T-tests
t.test(Walc ~ sex)
t.test(log10(Walc) ~ sex) 
t.test(Dalc ~ sex) 
t.test(log10(Dalc) ~ sex) 
t.test(studytime ~ sex) 
t.test(grade ~ sex)
t.test(grade ~ school) 
t.test(Walc ~ school) 
t.test(log10(Walc) ~ school) 
t.test(Dalc ~ school) 
t.test(log10(Dalc) ~ school) 
```
*Discussion of t-test results:*
**The results of a two-sample t-test showed that there was enough evidence to reject the null hypothesis that the difference in means of weekend and weekday alcohol consumption for Females and Males was equal to zero. This was also true on the log scale. Additionally, a t-test showed significant difference in study time and grades for females and males, and showed significant differences in grades between schools. There was not enough evidence to reject the null hypothesis that the difference in mean weekday alcohol consumption between schools was equal to zero. This was true on the log scale and for weekend alcohol consumption as well.**

```{r}
##correlations are already provided in the matrix plot above, should we do this again? 
#### perhaps we should do some, so we can provide some discussion of the results and talk about the statistical significance 
cor.test(Dalc, Walc)
cor.test(age, grade)
cor.test(freetime, goout)
cor.test(goout, Walc)

# any others that are important?
```


```{r}
#Bootstrap 1 of grades and Weekday Alcohol Consumption

#Recoding Dalc to a binary, for later use 
Dalc2 <- ifelse(Dalc == 1, "None", "Some")

#t test for the binary version of Dalc 
t.test(grade ~ Dalc2)

#Make normal quantile plot of grades
library(car)
qqPlot(grade, col = 2, pch = 18, main = "Normal Quantile Plot of Grades")

#Boxplot of grades by Dalc2
boxplot(grade ~ Dalc2, main = "Boxplot of Grades by Weekday Alcohol Consumption", cex.main = 0.7, col = c(2:4), lwd = 2)

#Count number of non-missing values in each level of weekday alcohol consumption
sum(Dalc2 == "None")
sum(Dalc2 == "Some")

#Set number of bootstrap samples to take
N <- 10000

#Make empty vector for sample mean differences
diffGrade <- rep(NA, N)

for (i in 1:N) {
  sN <- sample(grade[Dalc2 =="None"], sum(Dalc2 == "None"), replace = TRUE)
  sS <- sample(grade[Dalc2 =="Some"], sum(Dalc2 == "Some"), replace = TRUE)
  diffGrade[i] <- mean(sN) - mean(sS)
}

#Get bootstrap quantiles
ci <- quantile(diffGrade, c(0.025, 0.975))

#Report these values
round(ci,1)
#compare to original 95% CI for the mean
Gradet_test <- t.test(grade ~ Dalc2)$conf.int
round(Gradet_test,2)

#Make histogram of bootstrap sample means
hist(diffGrade, col = "blue", main = "Bootstrapped Sample Means Diff in Grades against Weekday Alcohol Consumption", cex.main = 0.7, xlab = "Grades", breaks = 50)

#Add lines to histogram for CI's
abline(v = ci, lwd = 3, col = "red")
abline(v = Gradet_test, lwd = 3, col = "green", lty = 2)
legend("topright", c("Original CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2,1))

#Normal quantile plot of the bootstrapped differences in means
qqPlot(diffGrade, pch = 19, col = 'red', main = "NQ Plot of Bootstrapped Differences in Means \n of Grades based on Weekday Alcohol Consumption")

```


```{r}
#Bootstrap 2 of grades and Walc (Weekend Alcohol Consumption)
Walc2 <- ifelse(Walc == 1, "None", "Some")

t.test(grade ~ Walc2)

boxplot(grade ~ Walc2, main = "Boxplot of Grades by Weekend Alcohol Consumption", cex.main = 0.7, col = c(2:4), lwd = 2)

N <- 10000
diffGradeW <- rep(NA, N)

for (i in 1:N) {
  sNW <- sample(grade[Walc2 =="None"], sum(Walc2 == "None"), replace = TRUE)
  sSW <- sample(grade[Walc2 =="Some"], sum(Walc2 == "Some"), replace = TRUE)
  diffGradeW[i] <- mean(sNW) - mean(sSW)
}

ciW <- quantile(diffGradeW, c(0.025, 0.975))
round(ciW,1)

Gradet_testW <- t.test(grade ~ Walc2)$conf.int
round(Gradet_testW,2)

hist(diffGradeW, col = "blue", main = "Bootstrapped Sample Means Diff in Grades against Weekend Alcohol Consumption", cex.main = 0.7, xlab = "Grades", breaks = 50)
abline(v = ciW, lwd = 3, col = "red")
abline(v = Gradet_testW, lwd = 3, col = "green", lty = 2)
legend("topright", c("Original CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2,1))

qqPlot(diffGradeW, pch = 19, col = 'red', main = "NQ Plot of Bootstrapped Differences in Means \n of Grades based on Weekend Alcohol Consumption")
```

```{r}
#Bootstrap 3 of Dalc and age using non-binary data (FOR TEJ AND FRANKIE: IF WE DO NOT PERCEIVE DALC AS CONTINUOUS PLEZ DELETE THIS)

#We have jitter plot for Dalc vs age above

#Calculate the correlation
(cor1 <- cor(age, Dalc))

#Test if correlation is non-zero
cor.test(age, Dalc)

#Fit simple linear regression
lm1 <- lm(Dalc ~ age)
summary(lm1) 

#Do bootstrap
n_samp <- 10000

corResults <- rep(NA, n_samp)
bResults <- rep(NA, n_samp) 

for(i in 1:n_samp){
  s <- sample(1:634, 634, replace = T)
  fakeData <- cbind(age[s], Dalc[s])
  
  #Get bootstrapped correlation and regression slope
  corResults[i] <- cor(fakeData[, 1], fakeData[, 2])
  bResults[i] <- lm(fakeData[, 2] ~ fakeData[, 1])$coef[2]
}

#Get percentiles for 2.5 and 97.5
ci_r <- quantile(corResults, c(.025, .975))
ci_slope <- quantile(bResults, c(.025, .975))

#Histogram of bootstrapped correlation values with CI's (both bootstrapped and theoretical)
hist(corResults, col = "blue", main = "Bootstrapped Correlations", xlab = "Sample Correlation", breaks = 50)
abline(v = ci_r, lwd = 3, col = "red")
abline(v = cor.test(age, Dalc)$conf.int, lwd = 3, col = "green", lty = 2)
legend(-0.3, 450, c("Theoretical CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2, 1))

library(car)
qqPlot(corResults, main = "NQ Plot of Bootstrapped Correlations")

#Histogram of bootstrapped regression slopes with CI's (both bootstrapped and theoretical)
hist(bResults, col = "blue", main = "Bootstrapped Slopes", xlab = "Sample Slope", breaks = 50)
abline(v = ci_slope, lwd = 3, col = "red")
abline(v = confint(lm1,'age'), lwd = 3, col = "green", lty = 2)
legend("topleft", c("Theoretical CI","Boot CI"), lwd = 3, col = c("green","red"), lty = c(2, 1))

qqPlot(bResults, main = "NQ Plot of Bootstrapped Regression Slopes")

#reminder of regression results
summary(lm1)
```
*Bootstrap Discussion*
**(lelan can you do this), comparison to t-test, also may need to adjust title of last bootstrap graphs**

```{r}
##Permutation test (grade by school)
(actualdiff <- by(grade, school, mean))
(actualdiff <- actualdiff[1] - actualdiff[2])
set.seed(1)
N <- 10000
diffvals <- rep(NA, N)
for (i in 1:N) {
  fakeschool <- sample(school)  # default is replace = FALSE
  diffvals[i] <- mean(grade[fakeschool == "GP"]) -  mean(grade[fakeschool == "MS"])
}

hist(diffvals, col = "yellow", main = "Permuted Sample Means Diff in Grades between Schools", xlab = "Grade Diff", breaks = 50, xlim = c(-1.2, 1.5))
abline(v = actualdiff, col = "blue", lwd = 3)
text(actualdiff - 0.1, 300 , paste("Actual Diff in Means =", round(actualdiff,2)),srt = 90)

mean(abs(diffvals) >= abs(actualdiff)) ## p-value is approximately 0
```

```{r}
##Permutation test (grade by sex)
(actualdiff1 <- by(grade, sex, mean))
(actualdiff1 <- actualdiff1[1] - actualdiff1[2])
set.seed(1)
N <- 10000
diffvals1 <- rep(NA, N)
for (i in 1:N) {
  fakesex <- sample(sex)  # default is replace = FALSE
  diffvals1[i] <- mean(grade[fakesex == "F"]) -  mean(grade[fakesex == "M"])
}

hist(diffvals1, col = "yellow", main = "Permuted Sample Means Diff in Grades between Sex", xlab = "Grade Diff", breaks = 50, xlim = c(-1.2, 1.5))
abline(v = actualdiff1, col = "blue", lwd = 3)
text(actualdiff1 - 0.1, 400 , paste("Actual Diff in Means =", round(actualdiff1,2)),srt = 90)

mean(abs(diffvals1) >= abs(actualdiff1)) ## p-value is approximately 0.0012
```
*Permutation Test Discussion*
**The result of the first permutation test was that there is enough evidence to reject the null hypothesis that the difference in means of grades between the schools is zero. The permuted p-value was approximately 0, which is similar to the theoretical p-value calculated earlier to be 6.261e-08. These p-values are below alpha 0.05 and therefore we reject the null.**
**The result of the second permutation test was that there is enough evidence to reject the null hypothesis that the difference in means of grades between males and females is zero. The permuted p-value was 0.0012, which is similar to the theoretical p-value calculated earlier to be 0.0009001. These p-values are below alpha 0.05 and therefore we reject the null.**

*Multiple Regression - Description of Plan*
Few sentence intro to plan for multiple regression, variables used, process, etc.

```{r}
# Multiple Regression to predict grade (Best Subsets Regression, Bayesian Information Criteria)
mod1 <- regsubsets(grade ~ ., data = selected_data, nvmax = 11)
mod1sum <- summary(mod1)
names(selected_data)[mod1sum$which[which.min(mod1sum$bic), ]][-1] # names of the predictors
gradeBIC <- selected_data[,mod1sum$which[which.min(mod1sum$bic), ]]
modfin <- lm(grade ~ ., data = gradeBIC)
summary(modfin) # summary of best model according to BIC

# TODO: pls check my work ^^^ ... it seems one of the chosen predictors (freetime) has a p-value greater than 0.05? 
### maybe R is using alpha = 0.10 and thats why it was included, also i think ur work looks good!
myResPlots2(modfin) # normal quantile and residual plot for model

```
*Multiple Regression - Residual Plots*
Normal Quantile Plot of residuals, plot of fits vs. residuals, discussion


*Multiple Regression - Results and Discussion*
Results of final model displayed. Discussion of R-squared, parameter direction and significance. Discussion of criteria used to choose final model

*Multiple Regression - MISC*
Transformations, heteroskedasticity, completeness, etc.

```{r}

#interaction plot - there does appear to be an interaction
interaction.plot(Walc, school, grade, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot of Walc and School")
interaction.plot(Dalc, school, grade, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot of Dalc and School")
interaction.plot(Walc, sex, grade, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot of Walc and Sex")
interaction.plot(Dalc, sex, grade, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot of Dalc and Sex")
interaction.plot(absences, Walc, grade, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot of Absences and Walc")
interaction.plot(absences, Dalc, grade, type = 'b', lwd = 3, col = c('red','blue','black'), main = "Interaction Plot of Absences and Dalc")
### these last two are uglyyyyy should we get rid of them or keep them? 

mod2 <- lm(grade ~ ., data = selected_data)
mod2 <- lm(grade ~ Walc*sex + absences*Walc + school + sex + age + studytime + higher + freetime + health + absences)
summary(mod2)
##can I not take out walc if it's in the interaction terms (help @ frankie)
##only significant interactions Walc and sex and Walc and absences


## anova
interaction.plot(Walc2, sex, grade, type = 'b', lwd = 3, col = c('red','blue'), main = "Interaction Plot of Walc2 and Sex")
gradeaov <- aov(grade ~ Walc2 + sex + Walc2*sex)
summary(gradeaov)
gradelm <- lm(grade ~ Walc2 + sex + Walc2*sex -1)
summary(gradelm)

#turn into one-way anova and use Tukey!
combo <- as.factor(paste(Walc2, sex))
gradeaov2 <- aov(grade ~ combo)
summary(gradeaov2)
summary.lm(gradeaov2)

par(mar = c(5, 15, 4, 2))
plot(TukeyHSD(gradeaov2), las = 1)

bartlett.test(grade, combo)
leveneTest(grade, combo)

myResPlots2(gradeaov)

sds <- tapply(grade, combo, sd)
print("Ratio of Max/Min Sample SD")
round(max(sds)/min(sds), 1)
oneway.test(grade ~ combo)

```
*ANOVA Discussion*
should have model, interaction plot if two way, discussion of results, Tukey comparisons, residual plots. 

**Conclusions**
a short paragraph
##remember to take our names off!!

